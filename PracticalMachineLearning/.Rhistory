data_sg<-subset(SG_Userjourney.201508,SG_Userjourney.201508$country_name=="Singapore")
data_sg<-subset(data_sg,!(data_sg$category_name=="Unknown"))
data_sg<-subset(data_sg,!(data_sg$category_name=="All_Users"))
#data_sg<-subset(data_sg,!(data_sg$category_name=="All_CC"))
data_sg<-subset(data_sg,data_sg$contract_name=="AMNET APAC | SG_Citibank")
data_sg$combined <-paste(data_sg$user_id,data_sg$ts,sep="")
#confirmed users
Confirmed_Fires<- subset(data_sg,data_sg$category_name=="Confirm_CC_LP_Premier")
Non_Confirmed_Fires<- subset(data_sg,!(data_sg$category_name=="Confirm_CC_LP_Premier"))
Non_Confirmed_Fires <- Non_Confirmed_Fires[ grep("All", Non_Confirmed_Fires$category_name) , ]
conf_time<-aggregate(Confirmed_Fires$ts,by=list(Confirmed_Fires$user_id),max)
conf_time<-rename(conf_time,conf_ts=x,user_id=Group.1)
conf_time$combined<-paste(conf_time$user_id,conf_time$x,sep="")
#merge
merge_data<-merge(conf_time,Non_Confirmed_Fires,by="user_id")
merge_data<-select(merge_data,user_id,conf_ts,ts,category_name)
merge_data$lapse<-merge_data$conf_ts-merge_data$ts
merge_data<-subset(merge_data,merge_data$lapse>0)
#next max time fire
max_time<-aggregate(merge_data$ts,by=list(merge_data$user_id),max)
max_time<-rename(max_time,max_ts=x,user_id=Group.1)
max_time$combined<-paste(max_time$user_id,max_time$x,sep="")
#newmerge
newmerge_data<-merge(max_time,merge_data,by="user_id")
newmerge_data$lapse<-newmerge_data$max_ts-newmerge_data$ts
newmerge_data<-subset(newmerge_data,newmerge_data$lapse==0)
newmerge_data$lapse<-1
#histogram
prev_page<-aggregate(newmerge_data$lapse,by=list(newmerge_data$category_name),sum)
prev_page<-rename(prev_page,Category=Group.1,Count=x)
prev_page<-arrange(prev_page,desc(Count))
View(prev_page)
sum(prev_page$Count)
length(unique(subset(data_sg,data_sg$category_name="All_CC"))
length(unique(subset(data_sg,data_sg$category_name=="All_CC"))
)
All_CC<-subset(data_sg,data_sg$category_name=="All_CC")
length(unique(All_CC$user_id))
All_Insurance<-subset(data_sg,data_sg$category_name=="All_Insurance")
length(unique(All_Insurance$user_id))
View(conf_time)
length(unique(conf_time$user_id))
#confirmed users
Confirmed_Fires<- subset(data_sg,data_sg$category_name=="Confirm_CC_LP_Premier")
Non_Confirmed_Fires<- subset(data_sg,!(data_sg$category_name=="Confirm_CC_LP_Premier"))
Non_Confirmed_Fires <- Non_Confirmed_Fires[ grep("All", Non_Confirmed_Fires$category_name) , ]
conf_time<-aggregate(Confirmed_Fires$ts,by=list(Confirmed_Fires$user_id),max)
conf_time<-rename(conf_time,conf_ts=x,user_id=Group.1)
conf_time$combined<-paste(conf_time$user_id,conf_time$x,sep="")
#merge
merge_data<-merge(conf_time,Non_Confirmed_Fires,by="user_id")
merge_data<-select(merge_data,user_id,conf_ts,ts,category_name)
merge_data$lapse<-merge_data$conf_ts-merge_data$ts
merge_data<-subset(merge_data,merge_data$lapse>0)
#next max time fire
max_time<-aggregate(merge_data$ts,by=list(merge_data$user_id),max)
max_time<-rename(max_time,max_ts=x,user_id=Group.1)
max_time$combined<-paste(max_time$user_id,max_time$x,sep="")
#newmerge
newmerge_data<-merge(max_time,merge_data,by="user_id")
newmerge_data$lapse<-newmerge_data$max_ts-newmerge_data$ts
View(prev_page)
newmerge_data<-subset(newmerge_data,newmerge_data$lapse==0)
write.csv(prev_page,"prev_page.csv")
View(data_sg)
SG_Userjourney.2015082 <- read.delim("~/Accounts/Citibank/SG_Userjourney 2015082.txt")
View(SG_Userjourney.2015082)
data<-SG_Userjourney.2015082
remove(SG_Userjourney.2015082)
referrer<-subset(data,data$key=="referrer")
path<-subset(data,data$key=="path")
View(path)
ThankYou<-subset(path,grepl("Thank",path$value))
View(ThankYou)
ThankYou<-select(ThankYou,user_id,ts,value)
ThankYou$combined<-paste(ThankYou$user_id,ThankYou$ts,sep="")
path$combined<-paste(path$user_id,path$ts,sep="")
View(path)
path<-select(path,user_id,ts,value,combined)
View(path)
merge<-merge(ThankYou,path,by="combined")
View(merge)
View(path)
View(merge)
View(ThankYou)
View(path)
View(path)
View(merge)
View(path)
View(ThankYou)
user1<-ThankYou$user_id[1]
user1.data<-subset(path,path$user_id==x)
user1.data<-subset(path,path$user_id==user1)
View(user1.data)
View(referrer)
View(ThankYou)
View(referrer)
referrer<-seelct(referrer,user_id,ts,value)
referrer<-selct(referrer,user_id,ts,value)
referrer<-select(referrer,user_id,ts,value)
referrer$combined<-paste(referrer$user_id,referrer_ts,sep="")
referrer$combined<-paste(referrer$user_id,referrer$ts,sep="")
merge<-merge(ThankYou,referrer,by="combined")
View(merge)
merge$count<-1
View(merge)
summary<-aggregate(count,by=list(value.y),sum)
summary<-aggregate(count,by=list(merge$value.y),sum)
summary<-aggregate(value$count,by=list(merge$value.y),sum)
summary<-aggregate(merge$count,by=list(merge$value.y),sum)
summary
View(summary)
summary<-arrange(summary,desc(x))
sum(summary$x)
View(ThankYou)
unique(ThankYou$value)
length(unique(ThankYou$user_id))
View(summary)
View(path)
View(ThankYou)
View(summary)
View(summary)
View(ThankYou)
View(merge)
View(summary)
View(data)
unique(data$key)
View(summary)
SG_Userjourney.2015083 <- read.delim("~/Accounts/Citibank/SG_Userjourney 2015083.txt")
View(SG_Userjourney.2015083)
data<-subset(SG_Userjourney.2015083,SG_Userjourney.2015083$country_name=="Singapore")
View(data)
data<-subset(SG_Userjourney.2015083,SG_Userjourney.2015083$country_name=="Singapore")
remove(SG_Userjourney.2015083)
referrer<-subset(data,data$key=="referrer")
path<-subset(data,data$key=="path")
View(path)
ThankYou<-subset(path,grepl("Thank",path$value))
View(ThankYou)
ThankYou<-select(ThankYou,user_id,ts,value)
ThankYou$combined<-paste(ThankYou$user_id,ThankYou$ts,sep="")
path$combined<-paste(path$user_id,path$ts,sep="")
View(path)
path<-select(path,user_id,ts,value,combined)
View(path)
merge<-merge(ThankYou,path,by="combined")
user1<-ThankYou$user_id[1]
user1.data<-subset(path,path$user_id==user1)
referrer<-select(referrer,user_id,ts,value)
referrer$combined<-paste(referrer$user_id,referrer$ts,sep="")
merge<-merge(ThankYou,referrer,by="combined")
merge$count<-1
summary<-aggregate(merge$count,by=list(merge$value.y),sum)
summary
View(summary)
summary<-arrange(summary,desc(x))
View(summary)
sum(summary$x)
write.csv(summary,"SG_BeforeConfirmation.csv",colheader=na)
write.csv(summary,"SG_BeforeConfirmation.csv")
View(merge)
user_data<-select(merge,user_id.x,value.y)
write.csv(user_data,"SG_BeforeConfirmation_users.csv")
View(user1.data)
View(user_data)
user_data<-rename(user_data,user_id=user_id.x,Referrer-value.y)
user_data<-rename(user_data,user_id==user_id.x,Referrer==value.y)
user_data<-rename(user_data,user_id=user_id.x,Referrer=value.y)
write.csv(user_data,"SG_BeforeConfirmation_users.csv")
SG_ConfirmedUsers_AudienceInsights <- read.delim("~/Accounts/Citibank/User Journey Query/SG_ConfirmedUsers_AudienceInsights.txt")
View(SG_ConfirmedUsers_AudienceInsights)
audience<-SG_ConfirmedUsers_AudienceInsights
audience$user_id[1]
x<-audience$user_id[1]
audmerge<-merge(audience,merge,by=user_id)
audmerge<-merge(audience,merge,by.x=user_id,by.y=user_id.x)
View(merge)
View(audience)
audience<-rename(audience,user_id.x==user_id)
audience<-rename(audience,user_id.x=user_id)
audmerge<-merge(audience,merge,by=user_id.x)
View(merge)
View(audience)
y<-min(audience$user_id.x)
z<-min(merge$user_id.x)
y<-max(audience$user_id.x)
z<-max(merge$user_id.x)
View(merge)
View(summary)
View(audience)
sub<-subset(merge,merge$user_id.x==y)
View(sub)
View(audience)
write.csv(audience,"audience.csv")
View(audience)
sub<-subset(audience,audience$user_id.x==z)
View(merge)
length(unique(merge$user_id.x))
View(summary)
sum(summary$x)
View(merge)
View(user_data)
length(unique(user_data$user_id))
write.csv(user_data,"user_data.csv")
View(ThankYou)
data<-subset(SG_Userjourney.2015083,SG_Userjourney.2015083$country_name=="Singapore")
remove(SG_Userjourney.2015083)
referrer<-subset(data,data$key=="referrer")
path<-subset(data,data$key=="path")
View(path)
ThankYou<-subset(path,grepl("SGGCB/apfa/genfm/ThankYou.do",path$value))
View(ThankYou)
ThankYou<-select(ThankYou,user_id,ts,value)
ThankYou$combined<-paste(ThankYou$user_id,ThankYou$ts,sep="")
path$combined<-paste(path$user_id,path$ts,sep="")
View(path)
path<-select(path,user_id,ts,value,combined)
View(path)
merge<-merge(ThankYou,path,by="combined")
user1<-ThankYou$user_id[1]
user1.data<-subset(path,path$user_id==user1)
referrer<-select(referrer,user_id,ts,value)
referrer$combined<-paste(referrer$user_id,referrer$ts,sep="")
merge<-merge(ThankYou,referrer,by="combined")
merge$count<-1
summary<-aggregate(merge$count,by=list(merge$value.y),sum)
summary
SG_Userjourney.2015083 <- read.delim("~/Accounts/Citibank/SG_Userjourney 2015083.txt")
View(SG_Userjourney.2015083)
data<-subset(SG_Userjourney.2015083,SG_Userjourney.2015083$country_name=="Singapore")
remove(SG_Userjourney.2015083)
referrer<-subset(data,data$key=="referrer")
path<-subset(data,data$key=="path")
View(path)
ThankYou<-subset(path,grepl("SGGCB/apfa/genfm/ThankYou.do",path$value))
View(ThankYou)
ThankYou<-select(ThankYou,user_id,ts,value)
ThankYou$combined<-paste(ThankYou$user_id,ThankYou$ts,sep="")
path$combined<-paste(path$user_id,path$ts,sep="")
View(path)
path<-select(path,user_id,ts,value,combined)
View(path)
merge<-merge(ThankYou,path,by="combined")
user1<-ThankYou$user_id[1]
user1.data<-subset(path,path$user_id==user1)
referrer<-select(referrer,user_id,ts,value)
referrer$combined<-paste(referrer$user_id,referrer$ts,sep="")
merge<-merge(ThankYou,referrer,by="combined")
merge$count<-1
summary<-aggregate(merge$count,by=list(merge$value.y),sum)
summary
View(summary)
sum(summary$x)
clean_data <- read.csv("~/Accounts/MBS/AMES/data/New/clean_data.csv")
View(clean_data)
clean_data$EndDate <-as.Date(clean_data$StayDate)
clean_data$EndYr<-as.numeric(format(clean_data$EndDate,format="%Y"))
clean_data$EndMth<-as.numeric(format(clean_data$EndDate,format="%m"))
list31<-c(1,3,5,7,8,10,12)
list30<-c(4,6,9,11)
list28<-c(2)
clean_data$EndDay<-ifelse(clean_data$EndMth %in% list31,31,ifelse(clean_data$EndMth %in% list28,28,ifelse(clean_data$EndMth %in% list30,30,0)))
clean_data$EndDate<-as.Date(paste(clean_data$EndYr,clean_data$EndMth,clean_data$EndDay,Sep="-"),format="%Y%m%d")
clean_data$leadtime_mthend<-clean_data$EndDate=clean_data$StayDate
clean_data$leadtime_mthend<-clean_data$EndDate-clean_data$StayDate
clean_data$leadtime_mthend<-as.numeric(clean_data$EndDate-clean_data$StayDate)
clean_data$EndDateSTR <- as.Date(strptime(clean_data$EndDate, "%m/%d/%Y"))
clean_data$StayDateSTR <- as.Date(strptime(clean_data$StayDate, "%m/%d/%Y"))
clean_data$LeadTimeEndDate <- clean_data$EndDateSTR - clean_data$StayDateSTR
clean_data$EndDateSTR <- as.Date(strptime(clean_data$EndDate, "%Y-%m-%d"))
clean_data$StayDateSTR <- as.Date(strptime(clean_data$StayDate, "%Y-%m-%d"))
clean_data$LeadTimeEndDate <- clean_data$EndDateSTR - clean_data$StayDateSTR
clean_data$LeadTimeEndDate <-clean_data$EndDate-as.Date(clean_data$StayDate,format="%Y-&m-%d")
clean_data$LeadTimeEndDate <-clean_data$EndDate-as.Date(clean_data$StayDate,format="%Y-%m-%d")
clean_data<-select(clean_data,-EndYr,-EndMth,-EndDay)
library(dplyr)
clean_data<-select(clean_data,-EndYr,-EndMth,-EndDay)
clean_data <- read.csv("~/Accounts/MBS/AMES/data/New/clean_data.csv")
View(clean_data)
clean_data$EndDate <-as.Date(clean_data$StayDate)
clean_data$EndYr<-as.numeric(format(clean_data$EndDate,format="%Y"))
clean_data$EndMth<-as.numeric(format(clean_data$EndDate,format="%m"))
list31<-c(1,3,5,7,8,10,12)
list30<-c(4,6,9,11)
list28<-c(2)
clean_data$EndDay<-ifelse(clean_data$EndMth %in% list31,31,ifelse(clean_data$EndMth %in% list28,28,ifelse(clean_data$EndMth %in% list30,30,0)))
clean_data$EndDate<-as.Date(paste(clean_data$EndYr,clean_data$EndMth,clean_data$EndDay,Sep="-"),format="%Y%m%d")
clean_data$LeadTimeEndDate <-clean_data$EndDate-as.Date(clean_data$StayDate,format="%Y-%m-%d")
clean_data<-select(clean_data,-EndYr,-EndMth,-EndDay)
write.csv(clean_data,clean_data.csv)
write.csv(clean_data,"clean_data.csv")
getwd()
clean_data$LeadTimeEndDate <-clean_data$EndDate-as.Date(clean_data$SearchDate,format="%Y-%m-%d")
write.csv(clean_data,clean_data.csv)
write.csv(clean_data,"clean_data.csv")
pnorm(70, mean = 80, sd = 10)
qnorm(0.95,mean=1100,sd=75)
run<-pnorm(95, mean = 1100, sd = 75)
qnorm(0.95,mean=1100,sd=(75/10))
pbinom(3,size=5,prob=0.5,lower.tail=FALSE)
pnorm(16,mean=15,sd=(10/10)) - pnorm(14,mean=16,sd=1)
pnorm(16,mean=15,sd=(10/10)) - pnorm(14,mean=15,sd=1)
ppois(10,lamda=15)
ppois(10,lambda=15)
---
title: "Assessment2"
author: "Yuani"
date: "23 August 2015"
output: html_document
---
This is an analysis of the ToothGrowth data in the R datasets package.
###1. Load the ToothGrowth data and perform basic exploratory data analyses.
```{r}
library(datasets)
data("ToothGrowth")
str(ToothGrowth)
head(ToothGrowth)
```
###2. Provide a basic summary of the data.
There are 60 observations, with 3 variables in this dataset. The 3 variables are len (Length), supp (Supplpement) and dose (dosage). Based on the varaibles available in this dataset, we hypothesize that the data was derived from an experiment done to measure the effects of Supplements and their dosages on the length of tooth grow.
The summary of the data set by each variable is as follow:
```{r}
summary(ToothGrowth)
```
We explore the data set to test for relationships between the variables.
```{r}
library(ggplot2)
plot1<- plot1<-ggplot(ToothGrowth, aes(x = as.factor(dose), y = len,fill=supp))+geom_boxplot()
plot1
```
The above plots display the following trends:
1. The higher the dosage, the longer the length of tooth growth
2. OJ supplement outperforms VC at each dosage level. The gap between performance however closes at the 2.0 dosage level. It is therefore not conclusive that OJ will always outperform VC.
###3. Use confidence intervals and/or hypothesis tests to compare tooth growth by supp and dose.
####By Dosage
To test the effect of dosage on tooth growth, we develop a null hypothesis where each supplement has the same effect on tooth growth for a given dosage.
$H_0: \mu_{OJ|0.5} = \mu_{VC_|0.5}$
$H_0: \mu_{OJ|1.0} = \mu_{VC_|1.0}$
$H_0: \mu_{OJ|2.0} = \mu_{VC_|2.0}$
```{r}
dose0.5 <- subset(ToothGrowth, dose == 0.5)
dose1.0 <- subset(ToothGrowth, dose == 1.0)
dose2.0 <- subset(ToothGrowth, dose == 2.0)
t0.5 <-t.test(len~supp,paired=false,var.equal=false,data=dose0.5)
t0.5 <-t.test(len~supp,paired=FALSE,var.equal=FALSE,data=dose0.5)
t0.5
t0.5 <-t.test(len~supp,paired=FALSE,var.equal=FALSE,data=dose0.5)
t1.0 <-t.test(len~supp,paired=FALSE,var.equal=FALSE,data=dose1.0)
t1.5 <-t.test(len~supp,paired=FALSE,var.equal=FALSE,data=dose1.5)
t0.5$p.value
Sample.Dataset.1 <- read.csv("D:/Bridge/Sample Dataset 1.csv")
View(Sample.Dataset.1)
data<-Sample.Dataset.1
remove(Sample.Dataset.1)
new<- data[rep(seq_len(nrow(data)), data$LOS),])
new<- data[rep(seq_len(nrow(data), data$LOS),])
new<- data[rep(seq_len(nrow(data), data$LOS),]
new<- data[rep(seq_len(nrow(data), data$LOS),]
data_table_daily <- data[rep(seq_len(nrow(data)), data$LOS),]
View(data_table_daily)
write.csv(data_table_daily,"sample dataset1_Cleaned.csv")
CID.Test...User_id_39295618 <- read.delim("C:/Users/ychen06/Desktop/CID-Test---User_id_39295618.txt")
View(CID.Test...User_id_39295618)
lilbrary(reshape)
library(reshape)
cid<-CID.Test...User_id_39295618
View(CID.Test...User_id_39295618)
View(CID.Test...User_id_39295618)
remove(CID.Test...User_id_39295618)
new<-data.frame(x1=cid$user_id,text=cid$cid, sep='_')
View(new)
View(cid)
View(new)
new<-data.frame(user_id=cid$user_id,ts=cid$ts,read.table(text=cid$cid, sep='_'))
new<-data.frame(user_id=cid$user_id,ts=cid$ts,read.table(cid$cid, sep='_'))
str(cid$cid)
new<-data.frame(user_id=cid$user_id,ts=cid$ts,read.table(as.string(cid$cid), sep='_'))
new<-data.frame(user_id=cid$user_id,ts=cid$ts,read.table(cid$cid, sep='_'))
cid<-read.table(cid,stringAsFactor=FALSE)
cid<-read.table(cid,stringAsFactors=FALSE)
cid<-read.table(cid,stringsAsFactors=FALSE)
new<-data.frame(user_id=cid$user_id,ts=cid$ts,read.table(cid$cid, split='_'))
new<-read.table(cid$cid, split='_'))
new<-read.table(cid$cid, split='_')
new<-read.table(cid$cid, sep='_')
new<-data.frame(cid$user_ud,cid$ts, do.call(rbind, strsplit(cid$cid, split = "_", fixed = TRUE)))
new<-data.frame(cid$user_ud,cid$ts, do.call(rbind, strsplit(as.character(cid$cid), split = "_", fixed = TRUE)))
tail(cid)
new<-data.frame(cid$user_ud,cid$ts, do.call(rbind, strsplit(as.character(cid$cid), split = "_")))
new<-data.frame(do.call(rbind, strsplit(as.character(cid$cid), split = "_")))
head(new)
new<-data.frame(cid$user_id,do.call(rbind, strsplit(as.character(cid$cid), split = "_")))
new<-data.frame(cid$user_id,cid$ts,do.call(rbind, strsplit(as.character(cid$cid), split = "_")))
View(new)
library(dplyr)
new<-rename(new,AdvID=X1,CampaignID=X2,PlacementID=X3,SiteID=X4,CreativeID=X5,AdID= X6, GeoID=X7)
View(new)
new$count<-1
site<-cast(new,cid.user_id,SiteID,value=count)
View(new)
site<-cast(new,cid.user_id~SiteID,sum,value=count)
str(new$cid.user_id)
str(new$SiteID)
site<-cast(new,as.factor(cid.user_id)~SiteID,sum,value=count)
site<-cast(new,as.character(cid.user_id)~SiteID,sum,value=count)
new$cid.user_id<-as.character(new$cid.user_id)
new$cid.user_id<-factor(new$cid.user_id)
site<-cast(new,cid.user_id~SiteID,sum,value=count)
site<-cast(new,list(cid.user_id)~SiteID,sum,value=count)
siteId<-unqiue(new$SiteID)
siteId<-distinct(new$SiteID)
siteId<-unqiue(new$SiteID)
siteId<-unqiue(list(new$SiteID))
siteId<-unqiue(list(new$SiteID))
install.packages('Rcpp')
print(cm1)
print(cm2)
---
title: "Practical Machine Learning"
author: "Yuani"
date: "19 November 2015"
output: html_document
---
##1. Download Data
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.
When importing data, all empty cells were replaced in "NA".str
```{r}
setwd("C:\\Users\\ychen06\\Documents\\IDA MOOC\\Git\\PracticalMachineLearning")
data_training<-read.csv("pml-training.csv",na.strings=c(""," ","NA"))
data_testing<-read.csv("pml-testing.csv",na.strings=c(""," ","NA"))
```
##Clean Dataset
There are 160 different variables in the datasets provided. However, not all variables can be used in developing  our predictions as the entire variable consist of null values.
We first clean the data set to select only variables with values that can be used for analysis.Columns with complete "NA" or blanks are removed.
We also generated a second table consisting of all the predictor variables and the final desired predicted value "classe". These variables were selected based on the goal of using data from accelerometers on the bell, forearm, arm and dumbbell.
```{r}
data_training_cleaned<-data_training[ , colSums(is.na(data_training))== 0 ]
data_predictor<- data_training_cleaned[,grepl("belt|forearm|arm|dumbbell|classe",names(data_training_cleaned))]
data_testing_cleaned<-data_testing[ , colSums(is.na(data_testing))== 0 ]
data_testing_cleaned<- data_testing_cleaned[,grepl("belt|forearm|arm|dumbbell|classe",names(data_testing_cleaned))]
```
This results in 53 variables including "classe" which is our predcted outcome.
```{r}
names(data_predictor)
```
The predicted outcomes in our training set is distributed as follow:
```{r}
summary(data_predictor$classe)
```
## Prediction Modeling
To create a check for our prediction model, we split the training set into 10 parts, 9 for training and 1 for cross validation. We first train a model using 9 folds, and test it on the 10th fold to check for accuracy.
```{r}
library(caret)
library(rpart)
```
```{r}
inTrain <- createDataPartition(y=data_predictor$classe, p=0.7, list=FALSE)
train_trainingset <- data_predictor[inTrain,]
train_testingset<- data_predictor[-inTrain,]
```
```{r}
set.seed(1212)
```
```{r}
#Decision Tree Method
modFit<-train(classe ~ . ,method="rpart",data=train_trainingset)
print(modFit$finalModel)
library(rattle)
rattle()
fancyRpartPlot(modFit$finalModel)
prediction_results_tree<-predict(modFit,newdata=train_testingset)
cm1<-confusionMatrix(prediction_results_tree, train_testingset$classe)
```
```{r}
#Random Forest Method
library(randomForest)
modFit2<-randomForest(classe~., data=train_trainingset, ntree = 500)
print(modFit2$finalModel)
prediction_results_rf<-predict(modFit2,newdata=train_testingset)
cm2<-confusionMatrix(prediction_results_rf, train_testingset$classe)
```
##Selection Prediction Model
Comparing the level of specificity and sensitivty bewteen the 2 models, the random forest shows better results, with an accuracy of 99%. We will therefore select the random forest model on the testing data set to predict the 'classe'.
```{r}
print(cm1)
print(cm2)
par(mfrow=c(1,2))
plot(cm1$byClass, main="classification tree")
text(labels=LETTERS[1:5], cex= 0.7)
plot(cm2$byClass, main="random forest",xlim=c(0.95,1.01),ylim=c(0.95,1.01))
text(labels=LETTERS[1:5], cex= 0.7)
```
##Prediction Results
```{r}
#model used
print(modFit2$finalModel)
prediction_results_final<-predict(modFit2,newdata=data_testing_cleaned)
final_table<-data_testing_cleaned
final_table$Prediction<-prediction_results_final
```
final_table
cm1
answers<-preduction_results_final
answers<-prediction_results_final
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
